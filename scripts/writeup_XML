Note on XML Evaluation

Problem Statements
------------------

P1 - Convert Textbox into table,list or textbox depending on the size, font and color of the text inside the textbox
P2 - Proper alignment of Images: if 1 image, then align center; if 2 images then align them right and left; if 3 images then align them left, center, right; if more than 3 images then leave them as it is
P3 - Change bullet colors in list depending on the color of the bullet itself and the color of the neighbour bullets
P4 - Change color,size of text in slide depending on the alignment of the image inside the slide
P5 - Change text style(bold, underline, italic) in textbox depending on font,size of text
P6 - Convert List into table, textbox or list depending on bullettype, size and font of text in list
P7 - Change text indentation in table depending on the border, font of text inside table. 

Dataset Generation
-------------------

For each of the cases, synthetic data is randomly generated in the following manner:

For all scenarios and all cases, the training dataset (which is used for clustering) contains 100 examples, tuning data (which is used for learning weights for features) contains 300 examples and test dataset contains 100 examples. Each example in all cases has around 3-4 attributes with each atrribute having on average 4-5 values. The values for the attributes are chosen randomly from a predescribed set of values.  A datapoint is said to be a confusion datapoint if it belongs to more than 1 cluster.

We first generate unconfused data points(data points which uniquely belong to a cluster) and append (input,output) to a list. Confusion datapoints are then generated by carefully generating points which belong to more than one cluster. For confusion datapoints, the output belongs to a unique output cluster given the datapoint follows a fixed constraint. This (input,output) is appended to the previous list. The list is then shuffled randomly in order to ensure that the order of examples does not effect our results. 

This approach is taken to generate all the datasets with a given confusion ratio. The test dataset also has 20%,40% and 60% confusion in scenarios S2,S3,S4. Note that, learning to rank is thus helpful since it helps us to judge how much a confusion datapoint in test follows the constraint and assign it to the appropriate input cluster.

Observations
------------

For all scenario's, it is expected that the accuracy will first increase with increasing confusion upto a certain threshold and start decreasing further due to more conflicting examples. However, this threshold will depend on the dataset itself. 

For most of the problem statements it was observed that the accuracy at 20% confusion > accuracy at 40% confusion > accuracy at 60% confusion. However, for scenario P3, the accuracy is below than the other scenarios since it is a special case where complete subsumption is happening in input LGGs. This increases the confusion leading to less accuracy.

Special case of 40% confusion + 20% unseen points:
Unseen points are those points which do not belong to any input cluster completely. Unseen points are generated by assigning a particular attribute a value which has not been used while generating train dataset (which is used for clustering). We have taken a simple case where all unseen points go to a single output cluster but get partially subsumed with all input clusters.

For this simple case, in all scenarios it is observed that the accuracy achieved is better than accuracy achieved in 60% confusion but not at par with accuracy achieved in 40% confusion. 

Time taken by Program
---------------------   

P1,P2,P4 require on an average ~30 seconds which includes clustering using training data, learning weights using tuning data and then getting the accuracy on tuning and test data for all scenarios S2-S5. Accordingly, P5,P6,P7 require on an average ~25 seconds. P3 requires ~15 seconds.